{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soroosh-N/Deep-learning-basics/blob/main/HW1_soroosh_noorzad_99205372.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbtO5Oa-xlWU"
      },
      "source": [
        "# **Deep learning assignment - 1st series<br/>**\n",
        "Soroosh Noorzad - 99205372<br/>\n",
        "soroosh.noorzad@gmail.com<br/>\n",
        "Phone : +989111853686<br/>\n",
        "Date : 1400.08"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **READ ME FIRST :**\n",
        "To See the results of **Question 1 parts**, please run the cells one by one untill reaching the answering sections.<br/>\n",
        "To See the results of **Question 2 parts**, please scroll down to the Q2 section, then run its cells.<br/>\n",
        "\n",
        "---\n",
        "\n",
        "Note that, we will have our necessary descriptions on the report of the assignment.\n",
        "\n",
        "---\n",
        "\n",
        "**Contents of the notebook :**\n",
        "*   Libraries (Q1)\n",
        "*   Functions (Q1)\n",
        "*   Datasets (Q1)\n",
        "*   Answer to section Q1.1\n",
        "*   Answer to section Q1.2-3-4-5-6\n",
        "*   Answer to section Q1.7\n",
        "*   Answer to section Q2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHYm7BrYZe-H"
      },
      "source": [
        "# **Libraries :**\n",
        "This is the place where all the libraries of the question one will be gathered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTMZaoey5G77",
        "outputId": "21bb0f2d-aa97-4a32-a545-e1352dee0ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ]
        }
      ],
      "source": [
        "# We should use tensorflow 1 in our project, so:\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version :', tf.__version__)\n",
        "\n",
        "# Other libraries\n",
        "import cv2\n",
        "import math\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from threading import Thread\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import ImageDraw, Image, ImageFont"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOlupMtDarZE"
      },
      "source": [
        "# **Functions :**\n",
        "All the general functions which can be used all over the project will be here to prevenet repition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vLxsMf9iaqtG"
      },
      "outputs": [],
      "source": [
        "def csv_file_to_numpy_array(csv_file):\n",
        "    \"\"\"\n",
        "    Convert this special dataset csv files to numpy arrays\n",
        "    :param csv_file:        input csv file\n",
        "    :return:                inputs and their corresponding labels\n",
        "    \"\"\"\n",
        "    x_df = csv_file.drop(csv_file.columns[0], axis=1).div(255).to_numpy()\n",
        "    y_df = csv_file.drop(csv_file.columns[1:], axis=1)\n",
        "    XX = []\n",
        "    for row in x_df:\n",
        "        XX.append(np.reshape(row, (28, 28)))\n",
        "    return np.array(XX), y_df[0].to_numpy()\n",
        "\n",
        "\n",
        "def line_def(string=\"-\", line_length=60):\n",
        "    \"\"\"\n",
        "    print a line on the output\n",
        "    :param string:          the character line made of\n",
        "    :param line_length:     the length of line\n",
        "    :return:                the line to be printed\n",
        "    \"\"\"\n",
        "    return ''.join(string for _ in range(line_length))\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap='Oranges'):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    :param cm:              Confusion Matrix\n",
        "    :param classes:         Labels to be printed on the plot\n",
        "    :param normalize:       Normalization can be applied by setting `normalize=True`.\n",
        "    :param title:           The plot title\n",
        "    :param cmap:            Color of the plot\n",
        "    :return:                nothing\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Labels')\n",
        "    plt.xlabel('Predictions')\n",
        "    plt.subplots_adjust(left=0.1, right=1, top=0.95, bottom=0.05)\n",
        "\n",
        "\n",
        "def bar_plot(input_vector, input_labels, input_texts):\n",
        "    \"\"\"\n",
        "    Print a bar plot from the input data\n",
        "    :param input_vector:        the input data\n",
        "    :param input_labels:        the classes to be counted\n",
        "    :param input_texts:         the titles and labels and other stuff of the plot\n",
        "    :return:                    nothing\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    t = [input_labels[i] for i in range(len(input_labels))]\n",
        "    count = [0 for _ in range(len(input_labels))]\n",
        "    for i, _ in enumerate(input_vector):\n",
        "        count[input_vector[i]] += 1\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.bar(t, count, color=\"#4CAF50\", width=0.3)\n",
        "    ax.set_title(input_texts[0])\n",
        "    ax.set_ylabel(input_texts[1])\n",
        "    ax.set_xlabel(input_texts[2])\n",
        "    # ax.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_2d(dimension, docs, label, legends, colors, plot_type=\"plot\", marker=\".\"):\n",
        "    \"\"\"\n",
        "    To plot 2d figures (With the use of matplotlib)\n",
        "    ----------\n",
        "    Parameters:\n",
        "        dimension (list): A list of all the sections of one figure, e.g. in 2x2 figs we have 221, 222, 223, 224 dims.\n",
        "        docs (list): This gonna be tricky. :) We included all the plots on this variable in such a format that we can\n",
        "        use this function under different situations.\n",
        "        label (list): A complex list of labels for all the plots in each figure.\n",
        "        legends (list): A list of corresponding legends to describe every curve in the plots.\n",
        "        colors (list): A list of corresponding colors for every curve we see in the plots.\n",
        "        plot_type (str): Should we sketch the main curve by scattering or plotting? or maybe histogram?\n",
        "        marker (str): The main plot marker.\n",
        "    ----------\n",
        "    Returns:\n",
        "        (Object) The function will return the created figure (by the use of matplotlib).\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    for i, d in enumerate(docs):\n",
        "        ax = fig.add_subplot(dimension[i])\n",
        "        t1 = np.arange(0, len(d[0]), 1)\n",
        "        for j in range(len(d)):\n",
        "            if plot_type == \"scatter\":\n",
        "                ax.scatter(t1, d[j], color=(colors[j]), marker=marker, label=legends[j])\n",
        "                ax.set_ylim(bottom=-1.1, top=1.1)\n",
        "            else:\n",
        "                # simple plotting\n",
        "                ax.plot(t1, d[j], color=(colors[j]), label=legends[j])\n",
        "        ax.set_title(label[0][i])\n",
        "        ax.set_xlabel(label[1])\n",
        "        ax.set_ylabel(label[2])\n",
        "        ax.grid(which='both')\n",
        "        ax.legend(loc=\"best\")\n",
        "        # manager = plt.get_current_fig_manager()\n",
        "        # manager.window.showMaximized()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def print_res(figs, titles, ext=\"pdf\"):\n",
        "    \"\"\"\n",
        "    This is a function of saving final plots to the output files\n",
        "    ----------\n",
        "    Parameters:\n",
        "        figs (list): A list of figure objects, produced with matplotlib.\n",
        "        titles (list): A list of titles corresponding to the figures given above. We use these as output file names.\n",
        "        ext (str): What extension(type) are the final outputs.\n",
        "    ----------\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "    # Let's sleep one second. Don't rush! The figures are not ready yet! A little latency will results better pictures!\n",
        "    time.sleep(1)\n",
        "    for i, fig in enumerate(figs):\n",
        "        fig.savefig(titles[i] + \".\" + ext)\n",
        "\n",
        "\n",
        "def remove_uniformly(x_data, y_data, label_position, how_much=5):\n",
        "    \"\"\"\n",
        "    This function will remove samples from dataset and leave one of 'how_much' samples to be untouched\n",
        "    :param x_data:              input data to be sampled\n",
        "    :param y_data:              labels to be sampled\n",
        "    :param label_position:      what label to be removed uniformly\n",
        "    :param how_much:            how is the sampling rate\n",
        "    :return:                    the sampled dataset\n",
        "    \"\"\"\n",
        "    c = 0\n",
        "    members_to_delete = []\n",
        "    for index, y in enumerate(y_data):\n",
        "        if y == label_position-1:\n",
        "            c += 1\n",
        "            if c == how_much:\n",
        "                c = 0\n",
        "            else:\n",
        "                members_to_delete.append(index)\n",
        "    x_data = np.delete(x_data, members_to_delete, axis=0)\n",
        "    y_data = np.delete(y_data, members_to_delete)\n",
        "    return x_data, y_data\n",
        "\n",
        "\n",
        "def confusion_accuracy(confusion_matrix):\n",
        "    \"\"\"\n",
        "    This function will provide accuracy of each of confusion matrix labels\n",
        "    :param confusion_matrix:        The confusion matrix\n",
        "    :return:                        A list of labels accuracy, and! mean of that list\n",
        "    \"\"\"\n",
        "    labels_acc = [0 if sum(row) == 0 else round(row[index] / sum(row), 2) for index, row in enumerate(confusion_matrix)]\n",
        "    mean_accuracy = round(sum(labels_acc)/len(labels_acc), 2)\n",
        "    return labels_acc, mean_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhlcaDDfcDY0"
      },
      "source": [
        "# **Datasets :**\n",
        "Loading dataset from google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxSA6H62QFlN",
        "outputId": "68eae46b-f549-4b4b-adf9-a4194cd372a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n",
        "          'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
        "          'T', 'U', 'V', 'W', 'X', 'Y']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgxamSd2a-Fc"
      },
      "source": [
        "# **Answer to section Q1.1 :**\n",
        "Printing the first 25 pictures of the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "1DWZEiqcbLNc",
        "outputId": "3958a22e-0d9a-4005-9e03-ecea774ffbfa"
      },
      "outputs": [],
      "source": [
        "csv_train = pd.read_csv('gdrive/MyDrive/golab/datasets/Q1_train.csv', sep=',', skiprows=1, header=None)\n",
        "x_train, y_train = csv_file_to_numpy_array(csv_train)\n",
        "\n",
        "for index, picture in enumerate(x_train):\n",
        "    if index < 25:\n",
        "        img = Image.fromarray(np.uint8(picture * 255), 'L')\n",
        "        plt.subplot(5, 5, index+1)\n",
        "        plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
        "        plt.subplots_adjust(bottom=0.1, top=0.9, wspace=None, hspace=1)\n",
        "        plt.title(\"#\"+str(index) + \" : \" + str(labels[y_train[index]]), fontsize=8)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "    else:\n",
        "        break\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8UEiBiIsqaL"
      },
      "source": [
        "# **Answer to section Q1.2-3-4-5-6 :**\n",
        "In this section we created a procedure to handle all the sections of this question. With just changing the hyper-parameters we can answer different questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5bOJyt3stNK"
      },
      "outputs": [],
      "source": [
        "csv_train = pd.read_csv('gdrive/MyDrive/golab/datasets/Q1_train.csv', sep=',', skiprows=1, header=None)\n",
        "csv_test = pd.read_csv('gdrive/MyDrive/golab/datasets/Q1_test.csv', sep=',', skiprows=1, header=None)\n",
        "\n",
        "x_train, y_train = csv_file_to_numpy_array(csv_train)\n",
        "x_test, y_test = csv_file_to_numpy_array(csv_test)\n",
        "\n",
        "# TODO : Constants:\n",
        "# dataset class count\n",
        "class_count = 25\n",
        "\n",
        "# TODO : Hyper-parameters\n",
        "learning_rate = 0.1\n",
        "batch_size = 128\n",
        "seed_number = 35427\n",
        "valid_data_percentage = 0.2\n",
        "epoch_count = 150\n",
        "# ADAM or not? (if False then SGD)\n",
        "ADAM_opt = False\n",
        "# Setting for showing results at the end :\n",
        "display_step = 1\n",
        "# Dropout\n",
        "dropout_apply = False\n",
        "dropout_rate = 0.5\n",
        "# Layers setting (count, dropout, ReLU, bath_norm):\n",
        "layers_neuron_count = [784, 128, 128, class_count]\n",
        "dropout = [\n",
        "    (dropout_apply, dropout_rate),\n",
        "    (dropout_apply, dropout_rate),\n",
        "    (False, 0)\n",
        "]\n",
        "relus = [True, True, False]\n",
        "batch_norm = [False, False, False]\n",
        "# Do we want to remove \"THAT\" char uniformly?\n",
        "# [True or False, THAT_char_position]\n",
        "# E character is the 5th character in labels. so position = 5\n",
        "remove_char = [False, 5]\n",
        "\n",
        "\n",
        "# TODO : Functions:\n",
        "def fc_layer(previous_layer, layer_def, training):\n",
        "    layer = tf.add(tf.matmul(previous_layer, layer_def[0][0]), layer_def[0][1])\n",
        "    if layer_def[1][0]:\n",
        "        layer = tf.nn.dropout(layer, keep_prob=(1-layer_def[1][1]))\n",
        "    if layer_def[2]:\n",
        "        layer = tf.nn.relu(layer)\n",
        "    if layer_def[3]:\n",
        "        layer = tf.layers.batch_normalization(layer, training=training)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def neural_network(input_matrix, layers_def, training):\n",
        "    hidden = tf.layers.flatten(input_matrix)\n",
        "    for layer_def in layers_def:\n",
        "        hidden = fc_layer(hidden, layer_def, training)\n",
        "    return hidden\n",
        "\n",
        "\n",
        "# TODO : Pre-processes:\n",
        "[height, width] = x_train.shape[1:]\n",
        "num_test = x_test.shape[0]\n",
        "num_train = int((1-valid_data_percentage) * x_train.shape[0])\n",
        "steps = math.floor(num_train/batch_size)\n",
        "\n",
        "x_valid = x_train[num_train:]\n",
        "y_valid = y_train[num_train:]\n",
        "\n",
        "x_train = x_train[0:num_train]\n",
        "y_train = y_train[0:num_train]\n",
        "\n",
        "# Sample from \"THAT!\" special char, uniformly :\n",
        "if remove_char[0]:\n",
        "    # I made up remove_uniformly from myself. look at functions section.\n",
        "    x_train, y_train = remove_uniformly(x_train, y_train, remove_char[1], 5)\n",
        "\n",
        "print(\"Total records :\", x_train.shape[0]+x_valid.shape[0])\n",
        "print(\"Train records count :\", x_train.shape[0])\n",
        "print(\"Valid records count :\", x_valid.shape[0])\n",
        "print(\"Batch size :\", batch_size)\n",
        "print(\"Epoch count :\", epoch_count)\n",
        "\n",
        "# finalizing the data precesses\n",
        "with tf.Session() as sess:\n",
        "    y_train_hot = sess.run(tf.one_hot(y_train, class_count))\n",
        "    y_valid_hot = sess.run(tf.one_hot(y_valid, class_count))\n",
        "    y_test_hot = sess.run(tf.one_hot(y_test, class_count))\n",
        "    x_train_shuffle = sess.run(tf.random.shuffle(x_train, seed=seed_number))\n",
        "    y_train_shuffle = sess.run(tf.random.shuffle(y_train_hot, seed=seed_number))\n",
        "\n",
        "# TODO : Make Network graph\n",
        "# To clear the defined variables and operations of the previous cell\n",
        "tf.reset_default_graph()\n",
        "# tf Graph inputs (X for input data and Y for output labels)\n",
        "T = tf.placeholder(dtype=tf.bool, name='TRAINING')\n",
        "X = tf.placeholder(dtype=tf.float32, shape=(None, width, height), name='INPUT')\n",
        "Y = tf.placeholder(dtype=tf.float32, shape=(None, class_count), name='OUTPUT')\n",
        "# defining weights\n",
        "w = [\n",
        "    tf.get_variable(\n",
        "        dtype=tf.float32,\n",
        "        shape=(layers_neuron_count[i], layers_neuron_count[i+1]),\n",
        "        name='W'+str(i+1),\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.001)) for i in range(len(layers_neuron_count)-1)\n",
        "]\n",
        "# defining biases\n",
        "b = [\n",
        "    tf.get_variable(\n",
        "        dtype=tf.float32,\n",
        "        shape=layers_neuron_count[i+1],\n",
        "        name='B'+str(i+1),\n",
        "        initializer=tf.zeros_initializer()) for i in range(len(layers_neuron_count)-1)\n",
        "]\n",
        "layers_definition = [[[w[i], b[i]], dropout[i], relus[i], batch_norm[i]] for i in range(len(layers_neuron_count)-1)]\n",
        "# create the model\n",
        "logits = neural_network(X, layers_definition, T)\n",
        "\n",
        "# _op suffix means \"TensorFlow Operations\", also known as \"Ops\"\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits, name='LOSS'))\n",
        "# In relation to the batch normalization, we have line below :\n",
        "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "# TODO : Setting up optimizer\n",
        "if ADAM_opt:\n",
        "    # ADAM optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='ADAM')\n",
        "else:\n",
        "    # SGD optimizer\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate, name='SGD')\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# TODO : Evaluate model\n",
        "softmax = tf.nn.softmax(logits, name=\"SOFTMAX\")\n",
        "prediction = tf.argmax(softmax, axis=1, name=\"PREDICTION\")\n",
        "y_labels = tf.argmax(Y, 1)\n",
        "correct_pred = tf.equal(prediction, y_labels)\n",
        "# defining accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"ACCURACY\")\n",
        "# defining confusion matrix\n",
        "cm = tf.confusion_matrix(labels=y_labels, predictions=prediction)\n",
        "# defining model initializer\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Model saver\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# TODO : Create Summaries\n",
        "# Create a summary to monitor weight tensors\n",
        "w_s = [tf.summary.histogram(\"layer_number_\" + str(i+1) + \"_weights\", w[i]) for i in range(len(layers_neuron_count)-1)]\n",
        "# Merge some of these summaries into a single op for train dataset\n",
        "train_merged_op = tf.summary.merge(w_s)\n",
        "\n",
        "# Create a summary to monitor cost tensor\n",
        "los_s = tf.summary.scalar(\"Loss_scalar\", loss_op)\n",
        "# Create a summary to monitor accuracy tensor\n",
        "acc_s = tf.summary.scalar(\"Accuracy_scalar\", accuracy)\n",
        "# Merge some of these summaries into a single op for test dataset\n",
        "test_merged_op = tf.summary.merge([los_s, acc_s])\n",
        "\n",
        "# We don't want to merge them all. we have two different goals.\n",
        "# merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "# TODO : Starting a session\n",
        "# Starting a time recorder\n",
        "t = time.time()\n",
        "with tf.Session() as sess:\n",
        "    # Initialization\n",
        "    sess.run(init)\n",
        "    # Pre-allocation\n",
        "    train_los_set, train_acc_set = [], []\n",
        "    valid_los_set, valid_acc_set = [], []\n",
        "    test_los_set, test_acc_set = [], []\n",
        "    # op to write logs to Tensorboard\n",
        "    summary_writer = tf.summary.FileWriter(\"logs_path/\", graph=tf.get_default_graph())\n",
        "    for epoch in range(epoch_count):\n",
        "        # Pre-allocation of train mean parameters\n",
        "        train_loss_avr = 0\n",
        "        train_accu_avr = 0\n",
        "        # Display results\n",
        "        num = ((epoch+1) / display_step) - int((epoch+1) / display_step)\n",
        "        if num == 0:\n",
        "            print(line_def(\"=\"))\n",
        "            print('Epoch = %s ' % (epoch+1))\n",
        "            print(line_def(), \"\\ntitle\", \"\\t\\t\\t\\tLoss\", '\\t\\tAccuracy', end=\"\\n\"+line_def()+\"\\n\")\n",
        "        for i in range(steps):\n",
        "            current_step = epoch * steps + i\n",
        "            # After shuffling the train data we feed them in the model to catch new values for every one of them\n",
        "            # By running train_op, we will train our model. we don't need any type of output for that.\n",
        "            # By running loss_op and accuracy we will catch those parameters as the model learns\n",
        "            f = {X: x_train_shuffle[i*batch_size: (i+1)*batch_size], Y: y_train_shuffle[i*batch_size: (i+1)*batch_size], T: True}\n",
        "            _, _, b_loss, b_acc, train_summary = sess.run([train_op, extra_update_ops, loss_op, accuracy, train_merged_op], feed_dict=f)\n",
        "            # Write logs at every iteration\n",
        "            summary_writer.add_summary(train_summary, current_step)  # scalar summaries\n",
        "            # Compute average loss\n",
        "            train_loss_avr += b_loss / steps\n",
        "            # Compute average accuracy\n",
        "            train_accu_avr += b_acc / steps\n",
        "        f_valid = {X: x_valid, Y: y_valid_hot, T: False}\n",
        "        f_test = {X: x_test, Y: y_test_hot, T: False}\n",
        "        # Calculate output parameters for valid records per epoch\n",
        "        valid_loss, valid_acc = sess.run([loss_op, accuracy], feed_dict=f_valid)\n",
        "        # Calculate output parameters for test records per epoch\n",
        "        test_loss, test_acc, test_summary = sess.run([loss_op, accuracy, test_merged_op], feed_dict=f_test)\n",
        "        # Write logs at every iteration\n",
        "        summary_writer.add_summary(test_summary, epoch * steps)  # Histogram summaries\n",
        "        # Gather results per epoch\n",
        "        train_los_set.append(train_loss_avr)\n",
        "        train_acc_set.append(train_accu_avr * 100)\n",
        "        valid_los_set.append(valid_loss)\n",
        "        valid_acc_set.append(valid_acc * 100)\n",
        "        test_los_set.append(test_loss)\n",
        "        test_acc_set.append(test_acc * 100)\n",
        "        if num == 0:\n",
        "            # Display results\n",
        "            print(\"Training\", \"\\t\\t\\t{:.4f}\".format(train_loss_avr), \"\\t\\t{:.1f}\".format(train_accu_avr * 100), \"%\")\n",
        "            # print(line_def(\".\"))\n",
        "            print('Validation', '\\t\\t\\t{:.4f}'.format(valid_loss), \"\\t\\t{:.1f}\".format(valid_acc*100), \"%\")\n",
        "            # print(line_def(\".\"))\n",
        "            print(\"Testing\\t\\t\\t\\t{:.4f}\".format(test_loss), '\\t\\t{:.1f}'.format(test_acc * 100), \"%\")\n",
        "            # print(line_def(), end=\"\\n\\n\")\n",
        "            print('Time passed :', int(time.time() - t))\n",
        "    # Evaluating confusion matrix\n",
        "    confusion_matrix = sess.run(cm, feed_dict={X: x_test, Y: y_test_hot, T: False})\n",
        "    # Save model weights to disk\n",
        "    save_path = saver.save(sess, \"saved_model\")\n",
        "    print(\"Model saved in file: %s\" % save_path)\n",
        "\n",
        "# TODO : Ending time recorder\n",
        "print('\\nProcessing time :', int(time.time() - t))\n",
        "labels_acc, mean_acc = confusion_accuracy(confusion_matrix)\n",
        "print(\"The most accurate label is\", labels[np.argmax(labels_acc)], \"with a percent of {:.1f}\".format(max(labels_acc)))\n",
        "print(\"The entire labels accuracy list :\", labels_acc)\n",
        "print(\"The mean of labels accuracy is {:.1f}%\".format(mean_acc * 100))\n",
        "\n",
        "# TODO : plot confusion matrix\n",
        "plot_confusion_matrix(confusion_matrix, labels)\n",
        "\n",
        "# TODO : plot labels scattering\n",
        "bar_plot(y_train, labels, [\"Train data scattering\", 'Repetition', 'Labels'])\n",
        "bar_plot(y_valid, labels, [\"Valid data scattering\", 'Repetition', 'Labels'])\n",
        "bar_plot(y_test, labels, [\"Test data scattering\", 'Repetition', 'Labels'])\n",
        "\n",
        "# TODO : plot loss and accuracy curves\n",
        "los_labels = [[\"Loss Plots\"], 'Epochs', 'Loss value']\n",
        "acc_labels = [[\"Accuracy Plots\"], 'Epochs', 'Accuracy %']\n",
        "colors = ['black', 'blue', 'brown']\n",
        "legends = ['Train data', 'Valid data', 'Test data']\n",
        "los_fig = plot_2d([111], [[train_los_set, valid_los_set, test_los_set]], los_labels, legends, colors)\n",
        "acc_fig = plot_2d([111], [[train_acc_set, valid_acc_set, test_acc_set]], acc_labels, legends, colors)\n",
        "figs = [los_fig, acc_fig]\n",
        "titles = [\"[00] Los_fig\", '[00] Acc_fig']\n",
        "thread = Thread(target=print_res, args=(figs, titles, \"jpg\"))\n",
        "thread.start()\n",
        "plt.show()\n",
        "\n",
        "# Play an audio beep. Any audio URL will do.\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Answer to Section Q1.7**\n",
        "In this part, we will get the saved model from the previous part and run the camera using this model to detect the hand gestures.\n",
        "Attention :\n",
        "*    Before running, please make sure to run every previous cells. This cell may be dependent on their results.\n",
        "*    To stop the video stream, just click on the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "    Returns:\n",
        "          img: OpenCV BGR image\n",
        "    \"\"\"\n",
        "    # decode base64 image\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    # convert bytes to numpy array\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    # decode numpy array into OpenCV BGR image\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "    Returns:\n",
        "        bytes: Base64 image byte string\n",
        "    \"\"\"\n",
        "    # convert array into PIL image\n",
        "    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    # format bbox into png for return\n",
        "    bbox_PIL.save(iobuf, format='png')\n",
        "    # format return string\n",
        "    bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "    return bbox_bytes\n",
        "\n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      video.remove();\n",
        "      div.remove();\n",
        "      video = null;\n",
        "      div = null;\n",
        "      stream = null;\n",
        "      imgElement = null;\n",
        "      captureCanvas = null;\n",
        "      labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "          \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "\n",
        "# dataset class count\n",
        "class_count = 25\n",
        "valid_data_percentage = 0.2\n",
        "\n",
        "# delete the current graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# import the graph from the file\n",
        "imported_graph = tf.train.import_meta_graph('saved_model.meta')\n",
        "\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "\n",
        "# run the session\n",
        "with tf.Session() as sess:\n",
        "    # restore the saved neural network model\n",
        "    imported_graph.restore(sess, 'saved_model')\n",
        "    # start streaming video from webcam\n",
        "    video_stream()\n",
        "    while True:\n",
        "        js_reply = eval_js('stream_frame(\"{}\", \"{}\")'.format(label_html, bbox))\n",
        "        if not js_reply:\n",
        "            break\n",
        "        # convert JS response to OpenCV Image\n",
        "        frame = js_to_image(js_reply[\"img\"])\n",
        "        # create transparent overlay for bounding box\n",
        "        bbox_array = np.zeros([480, 640, 4], dtype=np.uint8)\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        resize = cv2.resize(gray, (28, 28)) / 255\n",
        "        prediction, softmax = sess.run([\"PREDICTION:0\", \"SOFTMAX:0\"], feed_dict={\"INPUT:0\": [resize], \"OUTPUT:0\": [[0 for _ in range(class_count)]]})\n",
        "        text = labels[prediction[0]] + \" [\" + \"{:.2f}\".format(softmax[0][prediction[0]] * 100) + \" %]\"\n",
        "        cv2.putText(\n",
        "            bbox_array,                      # Frame to put\n",
        "            text,                       # Text to show\n",
        "            (10, 40),                   # Position\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,   # Font family\n",
        "            1,                          # Font size\n",
        "            (0, 0, 255),                # Font color\n",
        "            2,                          # Font Stroke\n",
        "            cv2.LINE_4                  # ?\n",
        "        )\n",
        "        bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "        bbox = bbox_to_bytes(bbox_array)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Answer to Section Q2 :**\n",
        "In this section, we added missing lines to the codes. After running the codes (one after each other) we will let the results to be saved on the notebook for viewers to see how the codes will ended up.<br/>\n",
        "We will describe what happened here on the report of assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
        "env = gym.make(\"CartPole-v0\").env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "print(\"state vector dim =\", state_dim)\n",
        "print(\"n_actions =\", n_actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "agent = MLPClassifier(\n",
        "    hidden_layer_sizes=(20, 20),\n",
        "    activation='tanh',\n",
        ")\n",
        "\n",
        "# initialize agent to the dimension of state space and number of actions\n",
        "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*    `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
        "*    `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape **[len(states), n_actions]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_session(env, agent, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a single game using agent neural network.\n",
        "    Terminate when game finishes or after :t_max: steps\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        \n",
        "        # use agent to predict a vector of action probabilities for state :s:\n",
        "        probs = agent.predict_proba([s])[0]\n",
        "\n",
        "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
        "        \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        # sample proportionally to the probabilities, don't just take the most likely action\n",
        "        a = np.random.choice(range(n_actions), size=1, p=probs)[0]\n",
        "        # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "    return states, actions, total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
        "print(\"states:\", np.stack(dummy_states))\n",
        "print(\"actions:\", dummy_actions)\n",
        "print(\"reward:\", dummy_reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CEM steps\n",
        "\n",
        "Deep CEM uses exactly the same strategy as the regular CEM.\n",
        "\n",
        "The only difference is that now each observation is not a number but a `float32` vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
        "\n",
        "    elite_states = [s for i in range(len(states_batch)) if rewards_batch[i]>=reward_threshold for s in states_batch[i]]\n",
        "    elite_actions = [a for i in range(len(actions_batch)) if rewards_batch[i]>=reward_threshold for a in actions_batch[i]]\n",
        "    \n",
        "    return elite_states, elite_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    A convenience function that displays training progress. \n",
        "    No cool math here, just charts.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    clear_output(True)\n",
        "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
        "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)], [0], [100], label=\"percentile\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_sessions = 100\n",
        "percentile = 80\n",
        "log = []\n",
        "\n",
        "for i in range(100):\n",
        "    # generate new sessions\n",
        "    sessions = [ generate_session(env, agent) for _ in range(n_sessions) ]\n",
        "\n",
        "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
        "\n",
        "    # elite_states, elite_actions = map(np.concatenate,[states_batch,actions_batch])\n",
        "    elite_states, elite_actions = select_elites(states_batch,actions_batch,rewards_batch,percentile)\n",
        "\n",
        "    agent.fit(elite_states, elite_actions)\n",
        "    # <YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
        "\n",
        "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
        "\n",
        "    if np.mean(rewards_batch) > 190:\n",
        "        print(\"You Win!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Record sessions\n",
        "\n",
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
        "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMhkJVxJ0PoxiiYf6x48fDm",
      "collapsed_sections": [
        "bHYm7BrYZe-H",
        "JhlcaDDfcDY0",
        "MOlupMtDarZE",
        "QnZ8Uxc6a3gd",
        "VgxamSd2a-Fc"
      ],
      "include_colab_link": true,
      "name": "HW1-soroosh-noorzad-99205372.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
